{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pydicom\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator # use this to generate more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/content/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.246.512.1002.1058214001.1267878993.1650415...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.25.4669378111734520225376815262123197003</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.246.512.1.2.0.4.397070732735579.1755416012...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25.253986991488355213316410237483051286906</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.25.61269522713157549205486841880699641492</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.25.95301085161359068904812759023575525475</td>\n",
       "      <td>abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.2.246.512.1.2.0.4.120699027219781.1785915121...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.25.40752906400399014196156034336759107300</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.2.246.512.1002.3876311061.1152214383.7426756...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.25.114910141166331878573043514141730007108</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SOPInstanceUID     Label\n",
       "0   1.2.246.512.1002.1058214001.1267878993.1650415...    normal\n",
       "1          2.25.4669378111734520225376815262123197003    normal\n",
       "2   1.2.246.512.1.2.0.4.397070732735579.1755416012...    normal\n",
       "3        2.25.253986991488355213316410237483051286906    normal\n",
       "4         2.25.61269522713157549205486841880699641492    normal\n",
       "..                                                ...       ...\n",
       "95        2.25.95301085161359068904812759023575525475  abnormal\n",
       "96  1.2.246.512.1.2.0.4.120699027219781.1785915121...    normal\n",
       "97        2.25.40752906400399014196156034336759107300    normal\n",
       "98  1.2.246.512.1002.3876311061.1152214383.7426756...    normal\n",
       "99       2.25.114910141166331878573043514141730007108    normal\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path / \"labels.csv\")\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['Label'] == \"abnormal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(df, batch_size):\n",
    "    num_samples = len(df)\n",
    "    steps_per_epoch = num_samples // batch_size\n",
    "    while True:\n",
    "        for i in range(steps_per_epoch):\n",
    "            batch_df = df[i*batch_size:(i+1)*batch_size]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "            for idx, (sop, lbl) in batch_df.iterrows():\n",
    "                ds = pydicom.dcmread(path / f\"DICOM/{sop}.dcm\")\n",
    "                img = ds.pixel_array.astype(float)\n",
    "                cropped = img[200:1300, 500:2700]\n",
    "                exposures_image = exposure.adjust_gamma(cropped, gamma=0.8)\n",
    "                cropped_norm = exposure.rescale_intensity(exposures_image, in_range='image', out_range=(0, 255))\n",
    "                resized_img = cv2.resize(cropped_norm, (1100, 550)) / 255.\n",
    "                label = 1 if lbl == \"abnormal\" else 0\n",
    "                batch_images.append(resized_img)\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            yield np.array(batch_images), np.array(batch_labels), batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create data generators for train and validation\n",
    "batch_size = 8\n",
    "train_data_generator = image_generator(train_df, batch_size)\n",
    "val_data_generator = image_generator(val_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 550, 1100, 1)]    0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 550, 1100, 3)      6         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 550, 1100, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 18, 35, 2048)      23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,112,519\n",
      "Trainable params: 524,807\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Ai\\iaaa\\project\\.venv\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "inputs = Input(shape=(550, 1100, 1))\n",
    "x = Conv2D(3, 1, 1, padding='same')(inputs)\n",
    "x = tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255)(x)  # Normalize pixel values between 0 and 1\n",
    "\n",
    "# Base model\n",
    "base_model = ResNet50(input_shape=(550, 1100, 3),\n",
    "                      include_top=False,\n",
    "                      weights='imagenet')\n",
    "base_model.trainable = False\n",
    "x = base_model(x)\n",
    "\n",
    "# Global average pooling and regularization\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Additional dense layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['mae', 'acc'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8,mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "steps_per_epoch = len(train_df) // batch_size\n",
    "validation_steps = len(val_df) // batch_size\n",
    "history = model.fit(train_data_generator, \n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    validation_data=val_data_generator,\n",
    "                    validation_steps=validation_steps,\n",
    "                    epochs=20,\n",
    "                    callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 550, 1100, 1)]    0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 550, 1100, 3)      6         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 550, 1100, 3)      0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 18, 35, 2048)      23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,112,519\n",
      "Trainable params: 524,807\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"best_model.h5\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 140s 15s/step - loss: 0.2858 - mae: 2.6708 - acc: 0.9176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2858302891254425, 2.6707539558410645, 0.91756272315979]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = image_generator(test_df, batch_size)\n",
    "evaluation = loaded_model.evaluate(test_generator, steps=len(test_df) // batch_size)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2b6ac9097afe1dd0bd801f86cac9aa829a997024471c4c61f068295c904e22b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
